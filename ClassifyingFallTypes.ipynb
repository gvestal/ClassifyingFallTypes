{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sys\\n!{sys.executable} -m pip install openpyxl\\n#'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "st = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def loadDataAsDataFrame(f_path):\n",
    "    '''\n",
    "        Given a path, loads a data set and puts it into a dataframe\n",
    "        - simplified mechanism\n",
    "    '''\n",
    "    df = pd.read_csv(f_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_text(raw_text):\n",
    "\n",
    "    # Replace/remove username\n",
    "    raw_text = re.sub('(@[A-Za-z0-9\\_]+)', '@username_', raw_text)\n",
    "    #stemming and lowercasing\n",
    "    words=[]\n",
    "    for w in raw_text.lower().split():\n",
    "        if not w in st and not w in ['.',',', '[', ']', '(', ')']:\n",
    "            words.append(w)\n",
    "            \n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "f_path = 'pdfalls.csv'\n",
    "data = loadDataAsDataFrame(f_path)\n",
    "\n",
    "texts = data['fall_description']\n",
    "classes = data['fall_class']\n",
    "ids = data['record_id']\n",
    "\n",
    "#PREPROCESS THE DATA\n",
    "texts_preprocessed=[preprocess_text(txt) for txt in texts]\n",
    "data['preprocessed_texts']=texts_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to convert our data text into a formal readable by metamaplite\n",
    "\n",
    "def csvTosldiwi(dataframe, outputFileName, feature):\n",
    "    file1 = open(outputFileName, \"w\", encoding=\"utf-8\")  \n",
    "        \n",
    "    for i, row in dataframe.iterrows():\n",
    "\n",
    "        #title=(row['Document'], row['Sentence'])\n",
    "        title=str(i)\n",
    "        text=row[feature]\n",
    "        output=title + \"|\" + text + \"\\n\"\n",
    "\n",
    "        file1.write(output) \n",
    "    \n",
    "    file1.close() \n",
    "    \n",
    "#csvTosldiwi(data, \"pdfallssldiwi.txt\", 'fall_description')\n",
    "#csvTosldiwi(data, \"pdfallsLocsldiwi.txt\", 'fall_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>1</th>\n",
       "      <th>Score</th>\n",
       "      <th>3</th>\n",
       "      <th>cnum</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>MMI</td>\n",
       "      <td>3.68</td>\n",
       "      <td>Falls</td>\n",
       "      <td>C0085639</td>\n",
       "      <td>[fndg]</td>\n",
       "      <td>Fall-text-23-\"fall\"-NN-0,\"Falls\"-text-0-\"falls...</td>\n",
       "      <td>text</td>\n",
       "      <td>140/4;247/5</td>\n",
       "      <td>N06.850.135.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Accidental Falls</td>\n",
       "      <td>C0000921</td>\n",
       "      <td>[inpo]</td>\n",
       "      <td>Falls-text-0-\"falls\"-NNS-0</td>\n",
       "      <td>text</td>\n",
       "      <td>247/5</td>\n",
       "      <td>N06.850.135.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Hand</td>\n",
       "      <td>C0018563</td>\n",
       "      <td>[bpoc]</td>\n",
       "      <td>Hands-text-5-\"hands\"-NNS-0</td>\n",
       "      <td>text</td>\n",
       "      <td>100/5</td>\n",
       "      <td>A01.378.800.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Stomach</td>\n",
       "      <td>C0038351</td>\n",
       "      <td>[bpoc]</td>\n",
       "      <td>Stomach-text-0-\"stomach\"-NN-0</td>\n",
       "      <td>text</td>\n",
       "      <td>67/7</td>\n",
       "      <td>A03.556.875.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.38</td>\n",
       "      <td>Stomach Diseases</td>\n",
       "      <td>C0038354</td>\n",
       "      <td>[dsyn]</td>\n",
       "      <td>Stomach-text-0-\"stomach\"-NN-0</td>\n",
       "      <td>text</td>\n",
       "      <td>67/7</td>\n",
       "      <td>C06.405.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>86</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Feces</td>\n",
       "      <td>C0015733</td>\n",
       "      <td>[bdsu]</td>\n",
       "      <td>Stool-text-0-\"stool\"-NN-0,\"Stool\"-text-0-\"stoo...</td>\n",
       "      <td>text</td>\n",
       "      <td>110/5;193/5</td>\n",
       "      <td>A12.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>86</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Shoulder</td>\n",
       "      <td>C0037004</td>\n",
       "      <td>[blor]</td>\n",
       "      <td>Shoulder-text-21-\"shoulder\"-NN-0</td>\n",
       "      <td>text</td>\n",
       "      <td>172/8</td>\n",
       "      <td>A01.378.800.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>86</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.38</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>C0009072</td>\n",
       "      <td>[mnob]</td>\n",
       "      <td>clothes-text-0-\"clothes\"-NNS-0</td>\n",
       "      <td>text</td>\n",
       "      <td>18/7</td>\n",
       "      <td>J01.637.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>87</td>\n",
       "      <td>MMI</td>\n",
       "      <td>12.43</td>\n",
       "      <td>S-adenosylmethionine</td>\n",
       "      <td>C0036002</td>\n",
       "      <td>[bacs, aapp, phsu]</td>\n",
       "      <td>SAMe-text-0-\"same\"-JJ-0</td>\n",
       "      <td>text</td>\n",
       "      <td>0/4</td>\n",
       "      <td>D03.633.100.759.590.138.264;D12.125.166.676.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>87</td>\n",
       "      <td>MMI</td>\n",
       "      <td>1.84</td>\n",
       "      <td>Falls</td>\n",
       "      <td>C0085639</td>\n",
       "      <td>[fndg]</td>\n",
       "      <td>Fall-text-0-\"fall\"-NN-0</td>\n",
       "      <td>text</td>\n",
       "      <td>8/4</td>\n",
       "      <td>N06.850.135.122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Title    1  Score                     3      cnum                   4  \\\n",
       "0        88  MMI   3.68                 Falls  C0085639              [fndg]   \n",
       "1        88  MMI   1.84      Accidental Falls  C0000921              [inpo]   \n",
       "2        88  MMI   1.84                  Hand  C0018563              [bpoc]   \n",
       "3        88  MMI   1.84               Stomach  C0038351              [bpoc]   \n",
       "4        88  MMI   1.38      Stomach Diseases  C0038354              [dsyn]   \n",
       "...     ...  ...    ...                   ...       ...                 ...   \n",
       "2747     86  MMI   1.84                 Feces  C0015733              [bdsu]   \n",
       "2748     86  MMI   1.84              Shoulder  C0037004              [blor]   \n",
       "2749     86  MMI   1.38              Clothing  C0009072              [mnob]   \n",
       "2756     87  MMI  12.43  S-adenosylmethionine  C0036002  [bacs, aapp, phsu]   \n",
       "2757     87  MMI   1.84                 Falls  C0085639              [fndg]   \n",
       "\n",
       "                                                      5     6            7  \\\n",
       "0     Fall-text-23-\"fall\"-NN-0,\"Falls\"-text-0-\"falls...  text  140/4;247/5   \n",
       "1                            Falls-text-0-\"falls\"-NNS-0  text        247/5   \n",
       "2                            Hands-text-5-\"hands\"-NNS-0  text        100/5   \n",
       "3                         Stomach-text-0-\"stomach\"-NN-0  text         67/7   \n",
       "4                         Stomach-text-0-\"stomach\"-NN-0  text         67/7   \n",
       "...                                                 ...   ...          ...   \n",
       "2747  Stool-text-0-\"stool\"-NN-0,\"Stool\"-text-0-\"stoo...  text  110/5;193/5   \n",
       "2748                   Shoulder-text-21-\"shoulder\"-NN-0  text        172/8   \n",
       "2749                     clothes-text-0-\"clothes\"-NNS-0  text         18/7   \n",
       "2756                            SAMe-text-0-\"same\"-JJ-0  text          0/4   \n",
       "2757                            Fall-text-0-\"fall\"-NN-0  text          8/4   \n",
       "\n",
       "                                                      8  \n",
       "0                                       N06.850.135.122  \n",
       "1                                       N06.850.135.122  \n",
       "2                                       A01.378.800.667  \n",
       "3                                       A03.556.875.875  \n",
       "4                                           C06.405.748  \n",
       "...                                                 ...  \n",
       "2747                                            A12.459  \n",
       "2748                                    A01.378.800.750  \n",
       "2749                                        J01.637.215  \n",
       "2756  D03.633.100.759.590.138.264;D12.125.166.676.18...  \n",
       "2757                                    N06.850.135.122  \n",
       "\n",
       "[468 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we take the sldiwi file, process it with metamap in a separate script,\n",
    "#then load it back into this program here:\n",
    "\n",
    "mmiLocDF=pd.read_csv(\"pdfallsLocsmmi.txt\", sep='|', header=None)\n",
    "mmiLocDF.columns=['Title', \"1\", \"Score\", \"3\", \"cnum\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "\n",
    "mmiDF=pd.read_csv(\"pdfallsmmi.txt\", sep='|', header=None)\n",
    "mmiDF.columns=['Title', \"1\", \"Score\", \"3\", \"cnum\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "mmiDF[mmiDF['Score']>=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the metamap data to our current dataframe\n",
    "\n",
    "def getCnumsForDF(df, mmidf):\n",
    "    allCnums=[]\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        title = (i)\n",
    "        mmiRows=mmidf[(mmidf['Title']==title) & (mmidf['Score']>=1)]\n",
    "        cnumList = mmiRows['cnum'].tolist()\n",
    "        \n",
    "        cnums=''\n",
    "        for cnum in cnumList: \n",
    "            cnums+=cnum + \" \"\n",
    "        allCnums.append(cnums)\n",
    "        \n",
    "    return allCnums\n",
    "\n",
    "dataCnums=getCnumsForDF(data, mmiDF)\n",
    "data['CNums']=dataCnums\n",
    "\n",
    "dataLocCnums=getCnumsForDF(data, mmiLocDF)\n",
    "data['LocCNums']=dataLocCnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform target varaibles into \"CoM\" and \"Other\" only\n",
    "\n",
    "yRaw = data['fall_class']\n",
    "yFeature=[]\n",
    "for y in yRaw:\n",
    "    if y=='CoM':\n",
    "        yFeature.append(y)\n",
    "    else:\n",
    "        yFeature.append('Other')\n",
    "\n",
    "data['target']=yFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>duration</th>\n",
       "      <th>fall_class</th>\n",
       "      <th>fall_study_day</th>\n",
       "      <th>fall_location</th>\n",
       "      <th>fall_description</th>\n",
       "      <th>preprocessed_texts</th>\n",
       "      <th>CNums</th>\n",
       "      <th>LocCNums</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.2</td>\n",
       "      <td>CoM</td>\n",
       "      <td>20</td>\n",
       "      <td>Home-kitchen</td>\n",
       "      <td>Home-kitchen. standing and turning forward too...</td>\n",
       "      <td>home-kitchen. standing turning forward quickly</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.2</td>\n",
       "      <td>CoM</td>\n",
       "      <td>30</td>\n",
       "      <td>living room</td>\n",
       "      <td>standing and turning</td>\n",
       "      <td>standing turning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.2</td>\n",
       "      <td>CoM</td>\n",
       "      <td>70</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>standing up. turned too fast. landed face down...</td>\n",
       "      <td>standing up. turned fast. landed face down. tu...</td>\n",
       "      <td>C0015663 C0242821 C1140621 C0015450</td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.2</td>\n",
       "      <td>CoM</td>\n",
       "      <td>130</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>I had a small bottle in my right hand. I was u...</td>\n",
       "      <td>small bottle right hand. using left hand guide...</td>\n",
       "      <td>C0043016 C0009932 C4321304 C0013769 C0018563 C...</td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.2</td>\n",
       "      <td>CoM</td>\n",
       "      <td>228</td>\n",
       "      <td>YMCA</td>\n",
       "      <td>Turned around and reached for the walker. Turn...</td>\n",
       "      <td>turned around reached walker. turned fast took...</td>\n",
       "      <td>C0015663 C0025219 C0456387 C0008902 C0220870 C...</td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.9</td>\n",
       "      <td>BoS</td>\n",
       "      <td>392</td>\n",
       "      <td>outside</td>\n",
       "      <td>Was loading things from grocery cart into car....</td>\n",
       "      <td>loading things grocery cart car. tripped trail...</td>\n",
       "      <td>C0406810 C0003798 C0004381 C1738809 C1505163 C...</td>\n",
       "      <td></td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.9</td>\n",
       "      <td>CoM</td>\n",
       "      <td>394</td>\n",
       "      <td>hotel bathroom</td>\n",
       "      <td>Stood up after using toilet, toilet was very l...</td>\n",
       "      <td>stood using toilet, toilet low. lost balance, ...</td>\n",
       "      <td>C1140607 C0036588 C0085732 C0222762</td>\n",
       "      <td>C0556989 C0040364</td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.9</td>\n",
       "      <td>CoM</td>\n",
       "      <td>456</td>\n",
       "      <td>home</td>\n",
       "      <td>Was walking from the kitchen into the living r...</td>\n",
       "      <td>walking kitchen living room, lost balance carr...</td>\n",
       "      <td>C0015663 C0036588</td>\n",
       "      <td></td>\n",
       "      <td>CoM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.4</td>\n",
       "      <td>BoS</td>\n",
       "      <td>374</td>\n",
       "      <td>Indian Trail - Chattahoochee River</td>\n",
       "      <td>Walking - Hiking. Tripped on an exposed root. ...</td>\n",
       "      <td>walking - hiking. tripped exposed root. [lande...</td>\n",
       "      <td>C0004600</td>\n",
       "      <td>C0385242 C0337050 C1143949</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>68</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>BoS</td>\n",
       "      <td>127</td>\n",
       "      <td>Home, in dining room.</td>\n",
       "      <td>Getting up from sitting in a chair. Feet were ...</td>\n",
       "      <td>getting sitting chair. feet crossed chair. mus...</td>\n",
       "      <td>C0037763 C1140621 C0026821 C0032167 C0016504 C...</td>\n",
       "      <td></td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  age  female  duration fall_class  fall_study_day  \\\n",
       "0          110   82    Male       7.2        CoM              20   \n",
       "1          110   82    Male       7.2        CoM              30   \n",
       "2          110   82    Male       7.2        CoM              70   \n",
       "3          110   82    Male       7.2        CoM             130   \n",
       "4          110   82    Male       7.2        CoM             228   \n",
       "..         ...  ...     ...       ...        ...             ...   \n",
       "111         64   61  Female       4.9        BoS             392   \n",
       "112         64   61  Female       4.9        CoM             394   \n",
       "113         64   61  Female       4.9        CoM             456   \n",
       "114         66   60    Male       2.4        BoS             374   \n",
       "115         68   58    Male       7.3        BoS             127   \n",
       "\n",
       "                          fall_location  \\\n",
       "0                          Home-kitchen   \n",
       "1                           living room   \n",
       "2                               kitchen   \n",
       "3                               Kitchen   \n",
       "4                                  YMCA   \n",
       "..                                  ...   \n",
       "111                             outside   \n",
       "112                      hotel bathroom   \n",
       "113                                home   \n",
       "114  Indian Trail - Chattahoochee River   \n",
       "115               Home, in dining room.   \n",
       "\n",
       "                                      fall_description  \\\n",
       "0    Home-kitchen. standing and turning forward too...   \n",
       "1                                 standing and turning   \n",
       "2    standing up. turned too fast. landed face down...   \n",
       "3    I had a small bottle in my right hand. I was u...   \n",
       "4    Turned around and reached for the walker. Turn...   \n",
       "..                                                 ...   \n",
       "111  Was loading things from grocery cart into car....   \n",
       "112  Stood up after using toilet, toilet was very l...   \n",
       "113  Was walking from the kitchen into the living r...   \n",
       "114  Walking - Hiking. Tripped on an exposed root. ...   \n",
       "115  Getting up from sitting in a chair. Feet were ...   \n",
       "\n",
       "                                    preprocessed_texts  \\\n",
       "0       home-kitchen. standing turning forward quickly   \n",
       "1                                     standing turning   \n",
       "2    standing up. turned fast. landed face down. tu...   \n",
       "3    small bottle right hand. using left hand guide...   \n",
       "4    turned around reached walker. turned fast took...   \n",
       "..                                                 ...   \n",
       "111  loading things grocery cart car. tripped trail...   \n",
       "112  stood using toilet, toilet low. lost balance, ...   \n",
       "113  walking kitchen living room, lost balance carr...   \n",
       "114  walking - hiking. tripped exposed root. [lande...   \n",
       "115  getting sitting chair. feet crossed chair. mus...   \n",
       "\n",
       "                                                 CNums  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                 C0015663 C0242821 C1140621 C0015450    \n",
       "3    C0043016 C0009932 C4321304 C0013769 C0018563 C...   \n",
       "4    C0015663 C0025219 C0456387 C0008902 C0220870 C...   \n",
       "..                                                 ...   \n",
       "111  C0406810 C0003798 C0004381 C1738809 C1505163 C...   \n",
       "112               C1140607 C0036588 C0085732 C0222762    \n",
       "113                                 C0015663 C0036588    \n",
       "114                                          C0004600    \n",
       "115  C0037763 C1140621 C0026821 C0032167 C0016504 C...   \n",
       "\n",
       "                        LocCNums target  \n",
       "0                                   CoM  \n",
       "1                                   CoM  \n",
       "2                                   CoM  \n",
       "3                                   CoM  \n",
       "4                                   CoM  \n",
       "..                           ...    ...  \n",
       "111                               Other  \n",
       "112           C0556989 C0040364     CoM  \n",
       "113                                 CoM  \n",
       "114  C0385242 C0337050 C1143949   Other  \n",
       "115                               Other  \n",
       "\n",
       "[116 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had a small bottle in my right hand. I was using my left hand to guide the walker.  Did not have control of the walker and should not have anything other than my hands on the walker at all times. knees! no serious injuries! just something on elbow. turn around and push myself up while holding on to the walker'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3]['fall_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'CoM': 81, 'Other': 35})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_clusters = {}\n",
    "\n",
    "def loadwordclusters():\n",
    "    infile = open('./50mpaths2',  \"r\", encoding=\"utf-8\")\n",
    "    for line in infile:\n",
    "        items = str.strip(line).split()\n",
    "        class_ = items[0]\n",
    "        term = items[1]\n",
    "        word_clusters[term] = class_\n",
    "    return word_clusters\n",
    "\n",
    "def getclusterfeatures(sent):\n",
    "    sent = sent.lower()\n",
    "    terms = nltk.word_tokenize(sent)\n",
    "    cluster_string = ''\n",
    "    for t in terms:\n",
    "        if t in word_clusters.keys():\n",
    "                cluster_string += 'clust_' + word_clusters[t] + '_clust '\n",
    "    return str.strip(cluster_string)\n",
    "\n",
    "loadwordclusters()\n",
    "\n",
    "class myVectorizer():\n",
    "    def __init__(self):\n",
    "        self.textVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "        self.clustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.cnumclustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.loccnumClusterVectorizer= CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "        #for normaluzation\n",
    "        self.maxs={}\n",
    "        self.mins={}\n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "            \n",
    "        allcnums=[]\n",
    "        allCNumLists=rows['CNums']\n",
    "        for cnumList in allCNumLists:\n",
    "            allcnums.append(cnumList)\n",
    "        \n",
    "        self.textVectorizer.fit(texts_preprocessed)\n",
    "        self.clustervectorizer.fit(clusters)\n",
    "        self.cnumclustervectorizer.fit(allcnums)  \n",
    "        \n",
    "        #fall location\n",
    "        allLoccnums=[]\n",
    "        allLocCNumLists=rows['LocCNums']\n",
    "        for cnumList in allLocCNumLists:\n",
    "            allLoccnums.append(cnumList)\n",
    "            \n",
    "        self.loccnumClusterVectorizer.fit(allLoccnums)  \n",
    "        \n",
    "        \n",
    "        #get ready to normalize all the other features\n",
    "        for feature in training_rows.columns:\n",
    "            values=training_rows[feature]\n",
    "            featureType=type(values[0])\n",
    "\n",
    "            if not featureType==str or featureType==int:\n",
    "                self.maxs[feature]=max(values)\n",
    "                self.mins[feature]=min(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "        \n",
    "        data_vectors = self.textVectorizer.transform(texts_preprocessed).toarray()\n",
    "        cluster_vectors = self.clustervectorizer.transform(clusters).toarray()\n",
    "\n",
    "        data_vectors = np.concatenate((data_vectors, cluster_vectors), axis=1)\n",
    "        \n",
    "        allcnums=rows['CNums']\n",
    "        cnum_cluster_vectors = self.cnumclustervectorizer.transform(allcnums).toarray()\n",
    "        allloccnums=rows['LocCNums']\n",
    "        loc_cnum_cluster_vectors = self.loccnumClusterVectorizer.transform(allloccnums).toarray()\n",
    "        \n",
    "        data_vectors = np.concatenate((data_vectors, cnum_cluster_vectors), axis=1)\n",
    "        data_vectors = np.concatenate((data_vectors, loc_cnum_cluster_vectors), axis=1)\n",
    "\n",
    "        \n",
    "        #tack on all the other numeric features\n",
    "        for feature in ['duration',]:\n",
    "            values=rows[feature]\n",
    "            normValues = np.array([getNormalizedList(values, self.maxs[feature], self.mins[feature])])\n",
    "            data_vectors=np.concatenate((data_vectors, normValues.T), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_hyperparam_space(params, pipeline, folds, training_texts, training_classes):#folds, x_train, y_train, x_validation, y_validation):\n",
    "        grid_search = GridSearchCV(estimator=pipeline, param_grid=params, refit=True, cv=folds, return_train_score=False, scoring='f1_macro',n_jobs=-1)\n",
    "        grid_search.fit(training_texts, training_classes)\n",
    "        return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_set_size = int(0.8*len(data))\n",
    "\n",
    "X=data\n",
    "y=data['target'].tolist()\n",
    "\n",
    "training_rows, test_rows, training_classes, test_classes = train_test_split(\n",
    "    X, y, train_size=training_set_size, random_state=42069)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmaxs={}\\nmins={}\\n\\nfor feature in training_rows.columns:\\n    #print(feature)\\n    values=training_rows[feature]\\n    featureType=type(values[0])\\n    \\n    if not featureType==str or featureType==int:\\n        maxs[feature]=max(values)\\n        mins[feature]=min(values)\\n        \\nprint(maxs)\\nprint(mins)\\n\\nfor feature in [\\'duration\\', \\'age\\']:\\n    print(feature)\\n    values=training_rows[feature]\\n    normValues = getNormalizedList(values, maxs[feature], mins[feature])\\n    for i in range(len(values)):\\n        print(values[i], \"\\t\", normValues[i])\\n    print(\"*********************\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def normalize(value, maxOfList, minOfList):\n",
    "    return (value - minOfList) / (maxOfList - minOfList)\n",
    "    \n",
    "def getNormalizedList(values, maxOfList, minOfList):\n",
    "    ret = []\n",
    "    for value in values:\n",
    "        ret.append(normalize(value, maxOfList, minOfList))\n",
    "        \n",
    "    return ret  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as prf1\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import f1_score as f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNB baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on held-out test set ... :\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizer = myVectorizer()\n",
    "\n",
    "#CLASSIFIER\n",
    "gnb_classifier = GaussianNB()\n",
    "grid_params = {}\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',gnb_classifier)])\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier\n",
    "\n",
    "Best hyperparameters:\n",
    "{'svm_classifier__C': 0.25, 'svm_classifier__kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'svm_classifier__C': 0.25, 'svm_classifier__kernel': 'linear'}\n",
      "All scores:\n",
      "Performance on held-out test set ... :\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "vectorizer = myVectorizer()\n",
    "\n",
    "#CLASSIFIER\n",
    "svm_classifier = svm.SVC(gamma='scale')\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('svm_classifier',svm_classifier)])\n",
    "\n",
    "grid_params = {\n",
    "     'svm_classifier__C': [0.25, .5,1,2,4,8,16,32,64,128],\n",
    "     'svm_classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(grid.best_params_)\n",
    "\n",
    "print('All scores:')\n",
    "#all_means = grid.cv_results_['mean_test_score']\n",
    "#all_standard_devs = grid.cv_results_['std_test_score']\n",
    "#all_params = grid.cv_results_['params']\n",
    "#for mean, std, params in zip(all_means, all_standard_devs, all_params ):\n",
    "#    print('Mean:',mean, 'Standard deviation:', std, 'Hyperparameters:',  params)\n",
    "\n",
    "c_ = grid.best_params_['svm_classifier__C']\n",
    "kernel_ = grid.best_params_['svm_classifier__kernel']\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Best hyperparameters:\n",
    "{'classifier__n_estimators': 30}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'classifier__n_estimators': 25}\n",
      "Optimal n found: 25\n",
      "Performance on held-out test set ... :\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "vectorizer = myVectorizer()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',rf)])\n",
    "#pipeline ensures vectorization happens in each fold of grid search \n",
    "#(you could code the entire process manually for more flexibility)\n",
    "\n",
    "grid_params = {\n",
    "     'classifier__n_estimators': np.arange(5,60,5)\n",
    "}\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(grid.best_params_)\n",
    "\n",
    "print('Optimal n found:', grid.best_params_['classifier__n_estimators'])\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "Best hyperparameters:\n",
    "{'classifier__n_neighbors': 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'classifier__n_neighbors': 4}\n",
      "Performance on held-out test set ... :\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vectorizer = myVectorizer()\n",
    "\n",
    "clf= KNeighborsClassifier()\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',clf)])\n",
    "#pipeline ensures vectorization happens in each fold of grid search \n",
    "#(you could code the entire process manually for more flexibility)\n",
    "\n",
    "grid_params = {\n",
    "     'classifier__n_neighbors': np.arange(1,20,1),\n",
    "}\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(grid.best_params_)\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Is it really data science if there isn't a neural network somewhere?\n",
    "\n",
    "Best hyperparameters:\n",
    "{'classifier__hidden_layer_sizes': (71,)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'classifier__hidden_layer_sizes': (71,)}\n",
      "Performance on held-out test set ... :\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "vectorizer = myVectorizer()\n",
    "\n",
    "clf= MLPClassifier()\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',clf)])\n",
    "#pipeline ensures vectorization happens in each fold of grid search \n",
    "#(you could code the entire process manually for more flexibility)\n",
    "\n",
    "#we'll just use one hidden layer\n",
    "layerParams=[]\n",
    "for n in range(1,101, 10):\n",
    "    layerParams.append(tuple([n]))\n",
    "    \n",
    "grid_params = {\n",
    "     'classifier__hidden_layer_sizes': layerParams,\n",
    "}\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(grid.best_params_)\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "That combines all of the classifiers above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'classifier__voting': 'soft'}\n",
      "Performance on held-out test set ... :\n",
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "svmc = svm.SVC(C=0.25, kernel='linear', gamma='scale', probability=True)\n",
    "rf = RandomForestClassifier(n_estimators=30)\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "nn=MLPClassifier(hidden_layer_sizes=(71,))\n",
    "\n",
    "en=VotingClassifier(estimators=[('SVM', svmc), ('RF', rf), \n",
    "                                (\"KNN\", knn), (\"NN\", nn)])\n",
    "\n",
    "vectorizer = myVectorizer()\n",
    "\n",
    "#SIMPLE PIPELINE\n",
    "pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',en)])\n",
    "#pipeline ensures vectorization happens in each fold of grid search \n",
    "#(you could code the entire process manually for more flexibility)\n",
    "    \n",
    "grid_params = {\n",
    "     'classifier__voting': ['soft', 'hard']\n",
    "}\n",
    "\n",
    "#SEARCH HYPERPARAMETERS\n",
    "folds = 5\n",
    "grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(grid.best_params_)\n",
    "\n",
    "#CLASSIFY AND EVALUATE \n",
    "predictions_test = grid.predict(test_rows)\n",
    "print('Performance on held-out test set ... :')\n",
    "\n",
    "print(accuracy_score(predictions_test,test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now evaluate them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t GaussianNB()\n",
      "Accuracy\t 0.7083333333333334\n",
      "F1 Macro\t 0.5213675213675213\n",
      "F1 Micro\t 0.7083333333333334\n",
      "Confusion Matrix\n",
      "[[1.    0.   ]\n",
      " [0.875 0.125]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.35135135 0.74736842]\n",
      "\t****************************************\n",
      "\n",
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t SVC(C=0.25, kernel='linear', probability=True)\n",
      "Accuracy\t 0.6666666666666666\n",
      "F1 Macro\t 0.49473684210526314\n",
      "F1 Micro\t 0.6666666666666666\n",
      "Confusion Matrix\n",
      "[[0.9375 0.0625]\n",
      " [0.875  0.125 ]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.33333333 0.7       ]\n",
      "\t****************************************\n",
      "\n",
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t RandomForestClassifier(n_estimators=30)\n",
      "Accuracy\t 0.6666666666666666\n",
      "F1 Macro\t 0.4\n",
      "F1 Micro\t 0.6666666666666666\n",
      "Confusion Matrix\n",
      "[[1. 0.]\n",
      " [1. 0.]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.33333333 0.45454545]\n",
      "\t****************************************\n",
      "\n",
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t KNeighborsClassifier(n_neighbors=1)\n",
      "Accuracy\t 0.5833333333333334\n",
      "F1 Macro\t 0.5714285714285714\n",
      "F1 Micro\t 0.5833333333333334\n",
      "Confusion Matrix\n",
      "[[0.5625 0.4375]\n",
      " [0.375  0.625 ]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.36461844 0.75018939]\n",
      "\t****************************************\n",
      "\n",
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t MLPClassifier(hidden_layer_sizes=(71,))\n",
      "Accuracy\t 0.7083333333333334\n",
      "F1 Macro\t 0.5213675213675213\n",
      "F1 Micro\t 0.7083333333333334\n",
      "Confusion Matrix\n",
      "[[1.    0.   ]\n",
      " [0.875 0.125]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.35135135 0.71896307]\n",
      "\t****************************************\n",
      "\n",
      "Best hyperparameters:\n",
      "{}\n",
      "Classifier\t VotingClassifier(estimators=[('SVM',\n",
      "                              SVC(C=0.25, kernel='linear', probability=True)),\n",
      "                             ('RF', RandomForestClassifier(n_estimators=30)),\n",
      "                             ('KNN', KNeighborsClassifier(n_neighbors=1)),\n",
      "                             ('NN', MLPClassifier(hidden_layer_sizes=(71,)))],\n",
      "                 voting='soft')\n",
      "Accuracy\t 0.7083333333333334\n",
      "F1 Macro\t 0.5213675213675213\n",
      "F1 Micro\t 0.7083333333333334\n",
      "Confusion Matrix\n",
      "[[1.    0.   ]\n",
      " [0.875 0.125]]\n",
      "Bootstrapping 95% confidence interval:\n",
      "[0.35135135 0.74912892]\n",
      "\t****************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Confidence Interval</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>[0.35135135135135137, 0.7473684210526316]</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC(C=0.25, kernel='linear', probability=True)</td>\n",
       "      <td>[0.33333333333333337, 0.7]</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier(n_estimators=30)</td>\n",
       "      <td>[0.3333333333333333, 0.45454545454545453]</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier(n_neighbors=1)</td>\n",
       "      <td>[0.36461844265837007, 0.7501893939393939]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(71,))</td>\n",
       "      <td>[0.35135135135135137, 0.718963068181818]</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VotingClassifier(estimators=[('SVM',\\n        ...</td>\n",
       "      <td>[0.35135135135135137, 0.7491289198606272]</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Classifier  \\\n",
       "0                                       GaussianNB()   \n",
       "1     SVC(C=0.25, kernel='linear', probability=True)   \n",
       "2            RandomForestClassifier(n_estimators=30)   \n",
       "3                KNeighborsClassifier(n_neighbors=1)   \n",
       "4            MLPClassifier(hidden_layer_sizes=(71,))   \n",
       "5  VotingClassifier(estimators=[('SVM',\\n        ...   \n",
       "\n",
       "                         Confidence Interval  F1 Macro  F1 Micro  \n",
       "0  [0.35135135135135137, 0.7473684210526316]  0.521368  0.708333  \n",
       "1                 [0.33333333333333337, 0.7]  0.494737  0.666667  \n",
       "2  [0.3333333333333333, 0.45454545454545453]  0.400000  0.666667  \n",
       "3  [0.36461844265837007, 0.7501893939393939]  0.571429  0.583333  \n",
       "4   [0.35135135135135137, 0.718963068181818]  0.521368  0.708333  \n",
       "5  [0.35135135135135137, 0.7491289198606272]  0.521368  0.708333  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "Confusion matrix whose i-th row and j-th column entry indicates the number of samples \n",
    "with true label being i-th class and prediced label being j-th class.\n",
    "\"\"\"\n",
    "\n",
    "gnb = GaussianNB()\n",
    "svmc = svm.SVC(C=0.25, kernel='linear', gamma='scale', probability=True)\n",
    "rf = RandomForestClassifier(n_estimators=30)\n",
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "nn=MLPClassifier(hidden_layer_sizes=(71,))\n",
    "en=VotingClassifier(estimators=[('SVM', svmc), ('RF', rf), \n",
    "                                (\"KNN\", knn), (\"NN\", nn)], \n",
    "                                      voting='soft')\n",
    "\n",
    "f1df=pd.DataFrame()\n",
    "\n",
    "for clf in [gnb, svmc, rf, knn, nn, en]:\n",
    "    vectorizer = myVectorizer()\n",
    "\n",
    "    #SIMPLE PIPELINE\n",
    "    pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',clf)])\n",
    "\n",
    "    grid_params = {}\n",
    "    #SEARCH HYPERPARAMETERS\n",
    "    folds = 5\n",
    "    grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "    print('Best hyperparameters:')\n",
    "    print(grid.best_params_)\n",
    "\n",
    "    #CLASSIFY AND EVALUATE \n",
    "    predictions_test = grid.predict(test_rows)\n",
    "    \n",
    "    print(\"Classifier\\t\", clf)\n",
    "\n",
    "    print (\"Accuracy\\t\", acc(predictions_test,test_classes))\n",
    "    macro=f1(predictions_test,test_classes, average='macro')\n",
    "    micro=f1(predictions_test,test_classes, average='micro')\n",
    "    print (\"F1 Macro\\t\", macro)\n",
    "    print (\"F1 Micro\\t\", micro)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(test_classes, predictions_test, labels=['CoM', 'Other'], normalize='true'))\n",
    "    \n",
    "    #bootstrap it\n",
    "    f1s=[]\n",
    "    for iteration in range(1000):\n",
    "        resampleIndexes=random.choices(range(len(predictions_test)), k=len(predictions_test))\n",
    "        resamplePreds=[predictions_test[i] for i in resampleIndexes]\n",
    "        resampleTrueClasses=[test_classes[i] for i in resampleIndexes]\n",
    "        thisF1=f1(resamplePreds,resampleTrueClasses, average='macro')\n",
    "        f1s.append(thisF1)\n",
    "        \n",
    "    print(\"Bootstrapping 95% confidence interval:\")\n",
    "    interval=np.percentile(f1s, [2.5, 97.5])\n",
    "    print(interval)\n",
    "    \n",
    "    print(\"\\t****************************************\\n\")\n",
    "    \n",
    "    entry={\"Classifier\": clf, \"F1 Macro\":macro, \"F1 Micro\":micro,\n",
    "              \"Confidence Interval\":interval}\n",
    "    f1df=f1df.append(entry, ignore_index=True)\n",
    "    \n",
    "f1df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The winner: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove fall duration\n",
    "class ablation1():\n",
    "    def __init__(self):\n",
    "        self.textVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "        self.clustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.cnumclustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.loccnumClusterVectorizer= CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "            \n",
    "        allcnums=[]\n",
    "        allCNumLists=rows['CNums']\n",
    "        for cnumList in allCNumLists:\n",
    "            allcnums.append(cnumList)\n",
    "        \n",
    "        self.textVectorizer.fit(texts_preprocessed)\n",
    "        self.clustervectorizer.fit(clusters)\n",
    "        self.cnumclustervectorizer.fit(allcnums)  \n",
    "        \n",
    "        #fall location\n",
    "        allLoccnums=[]\n",
    "        allLocCNumLists=rows['LocCNums']\n",
    "        for cnumList in allLocCNumLists:\n",
    "            allLoccnums.append(cnumList)\n",
    "            \n",
    "        self.loccnumClusterVectorizer.fit(allLoccnums)  \n",
    "            \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "        \n",
    "        data_vectors = self.textVectorizer.transform(texts_preprocessed).toarray()\n",
    "        cluster_vectors = self.clustervectorizer.transform(clusters).toarray()\n",
    "\n",
    "        data_vectors = np.concatenate((data_vectors, cluster_vectors), axis=1)\n",
    "        \n",
    "        allcnums=rows['CNums']\n",
    "        cnum_cluster_vectors = self.cnumclustervectorizer.transform(allcnums).toarray()\n",
    "        allloccnums=rows['LocCNums']\n",
    "        loc_cnum_cluster_vectors = self.loccnumClusterVectorizer.transform(allloccnums).toarray()\n",
    "        \n",
    "        data_vectors = np.concatenate((data_vectors, cnum_cluster_vectors), axis=1)\n",
    "        data_vectors = np.concatenate((data_vectors, loc_cnum_cluster_vectors), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)\n",
    "\n",
    "#remove metamap tags of locations\n",
    "class ablation2():\n",
    "    def __init__(self):\n",
    "        self.textVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "        self.clustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.cnumclustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "        #for normaluzation\n",
    "        self.maxs={}\n",
    "        self.mins={}\n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "            \n",
    "        allcnums=[]\n",
    "        allCNumLists=rows['CNums']\n",
    "        for cnumList in allCNumLists:\n",
    "            allcnums.append(cnumList)\n",
    "        \n",
    "        self.textVectorizer.fit(texts_preprocessed)\n",
    "        self.clustervectorizer.fit(clusters)\n",
    "        self.cnumclustervectorizer.fit(allcnums)  \n",
    "        \n",
    "        \n",
    "        #get ready to normalize all the other features\n",
    "        for feature in training_rows.columns:\n",
    "            values=training_rows[feature]\n",
    "            featureType=type(values[0])\n",
    "\n",
    "            if not featureType==str or featureType==int:\n",
    "                self.maxs[feature]=max(values)\n",
    "                self.mins[feature]=min(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "        \n",
    "        data_vectors = self.textVectorizer.transform(texts_preprocessed).toarray()\n",
    "        cluster_vectors = self.clustervectorizer.transform(clusters).toarray()\n",
    "\n",
    "        data_vectors = np.concatenate((data_vectors, cluster_vectors), axis=1)\n",
    "        \n",
    "        allcnums=rows['CNums']\n",
    "        cnum_cluster_vectors = self.cnumclustervectorizer.transform(allcnums).toarray()\n",
    "\n",
    "        data_vectors = np.concatenate((data_vectors, cnum_cluster_vectors), axis=1)\n",
    "\n",
    "        \n",
    "        #tack on all the other numeric features\n",
    "        for feature in ['duration',]:\n",
    "            values=rows[feature]\n",
    "            normValues = np.array([getNormalizedList(values, self.maxs[feature], self.mins[feature])])\n",
    "            data_vectors=np.concatenate((data_vectors, normValues.T), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)\n",
    "\n",
    "#remove metamap tags of fall descriptions\n",
    "class ablation3():\n",
    "    def __init__(self):\n",
    "        self.textVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "        self.clustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.loccnumClusterVectorizer= CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "        #for normaluzation\n",
    "        self.maxs={}\n",
    "        self.mins={}\n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "            \n",
    "        \n",
    "        self.textVectorizer.fit(texts_preprocessed)\n",
    "        self.clustervectorizer.fit(clusters)\n",
    "        \n",
    "        #fall location\n",
    "        allLoccnums=[]\n",
    "        allLocCNumLists=rows['LocCNums']\n",
    "        for cnumList in allLocCNumLists:\n",
    "            allLoccnums.append(cnumList)\n",
    "            \n",
    "        self.loccnumClusterVectorizer.fit(allLoccnums)  \n",
    "        \n",
    "        \n",
    "        #get ready to normalize all the other features\n",
    "        for feature in training_rows.columns:\n",
    "            values=training_rows[feature]\n",
    "            featureType=type(values[0])\n",
    "\n",
    "            if not featureType==str or featureType==int:\n",
    "                self.maxs[feature]=max(values)\n",
    "                self.mins[feature]=min(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        texts_preprocessed = []\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "        \n",
    "        data_vectors = self.textVectorizer.transform(texts_preprocessed).toarray()\n",
    "        cluster_vectors = self.clustervectorizer.transform(clusters).toarray()\n",
    "\n",
    "        data_vectors = np.concatenate((data_vectors, cluster_vectors), axis=1)\n",
    "        \n",
    "        allloccnums=rows['LocCNums']\n",
    "        loc_cnum_cluster_vectors = self.loccnumClusterVectorizer.transform(allloccnums).toarray()\n",
    "        \n",
    "        data_vectors = np.concatenate((data_vectors, loc_cnum_cluster_vectors), axis=1)\n",
    "\n",
    "        #tack on all the other numeric features\n",
    "        for feature in ['duration',]:\n",
    "            values=rows[feature]\n",
    "            normValues = np.array([getNormalizedList(values, self.maxs[feature], self.mins[feature])])\n",
    "            data_vectors=np.concatenate((data_vectors, normValues.T), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)\n",
    "\n",
    "#remove 50mpaths clusters of fall descriptions\n",
    "class ablation4():\n",
    "    def __init__(self):\n",
    "        self.textVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "        self.cnumclustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.loccnumClusterVectorizer= CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "        #for normaluzation\n",
    "        self.maxs={}\n",
    "        self.mins={}\n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        texts_preprocessed = []\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "            \n",
    "        allcnums=[]\n",
    "        allCNumLists=rows['CNums']\n",
    "        for cnumList in allCNumLists:\n",
    "            allcnums.append(cnumList)\n",
    "        \n",
    "        self.textVectorizer.fit(texts_preprocessed)\n",
    "        self.cnumclustervectorizer.fit(allcnums)  \n",
    "        \n",
    "        #fall location\n",
    "        allLoccnums=[]\n",
    "        allLocCNumLists=rows['LocCNums']\n",
    "        for cnumList in allLocCNumLists:\n",
    "            allLoccnums.append(cnumList)\n",
    "            \n",
    "        self.loccnumClusterVectorizer.fit(allLoccnums)  \n",
    "        \n",
    "        #get ready to normalize all the other features\n",
    "        for feature in training_rows.columns:\n",
    "            values=training_rows[feature]\n",
    "            featureType=type(values[0])\n",
    "\n",
    "            if not featureType==str or featureType==int:\n",
    "                self.maxs[feature]=max(values)\n",
    "                self.mins[feature]=min(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        texts_preprocessed = []\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            texts_preprocessed.append(preprocess_text(tr))\n",
    "        \n",
    "        data_vectors = self.textVectorizer.transform(texts_preprocessed).toarray()\n",
    "        \n",
    "        allcnums=rows['CNums']\n",
    "        cnum_cluster_vectors = self.cnumclustervectorizer.transform(allcnums).toarray()\n",
    "        allloccnums=rows['LocCNums']\n",
    "        loc_cnum_cluster_vectors = self.loccnumClusterVectorizer.transform(allloccnums).toarray()\n",
    "        \n",
    "        data_vectors = np.concatenate((data_vectors, cnum_cluster_vectors), axis=1)\n",
    "        data_vectors = np.concatenate((data_vectors, loc_cnum_cluster_vectors), axis=1)\n",
    "\n",
    "        \n",
    "        #tack on all the other numeric features\n",
    "        for feature in ['duration',]:\n",
    "            values=rows[feature]\n",
    "            normValues = np.array([getNormalizedList(values, self.maxs[feature], self.mins[feature])])\n",
    "            data_vectors=np.concatenate((data_vectors, normValues.T), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)\n",
    "    \n",
    "#remove the n-grams\n",
    "class ablation5:\n",
    "    def __init__(self):\n",
    "        self.clustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.cnumclustervectorizer = CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        self.loccnumClusterVectorizer= CountVectorizer(ngram_range=(1,1), max_features=1000)\n",
    "        \n",
    "        #for normaluzation\n",
    "        self.maxs={}\n",
    "        self.mins={}\n",
    "    \n",
    "    def fit(self, rows, y=None):\n",
    "        \n",
    "        #fall description\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        \n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "            \n",
    "        allcnums=[]\n",
    "        allCNumLists=rows['CNums']\n",
    "        for cnumList in allCNumLists:\n",
    "            allcnums.append(cnumList)\n",
    "        \n",
    "        self.clustervectorizer.fit(clusters)\n",
    "        self.cnumclustervectorizer.fit(allcnums)  \n",
    "        \n",
    "        #fall location\n",
    "        allLoccnums=[]\n",
    "        allLocCNumLists=rows['LocCNums']\n",
    "        for cnumList in allLocCNumLists:\n",
    "            allLoccnums.append(cnumList)\n",
    "            \n",
    "        self.loccnumClusterVectorizer.fit(allLoccnums)  \n",
    "        \n",
    "        \n",
    "        #get ready to normalize all the other features\n",
    "        for feature in training_rows.columns:\n",
    "            values=training_rows[feature]\n",
    "            featureType=type(values[0])\n",
    "\n",
    "            if not featureType==str or featureType==int:\n",
    "                self.maxs[feature]=max(values)\n",
    "                self.mins[feature]=min(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def transform(self, rows):\n",
    "        unprocessedTexts=rows['fall_description']\n",
    "        clusters=[]\n",
    "        for tr in unprocessedTexts:\n",
    "            # you can do more with the training text here and generate more features...\n",
    "            clusters.append(getclusterfeatures(tr))\n",
    "        \n",
    "        data_vectors = self.clustervectorizer.transform(clusters).toarray()\n",
    "        \n",
    "        allcnums=rows['CNums']\n",
    "        cnum_cluster_vectors = self.cnumclustervectorizer.transform(allcnums).toarray()\n",
    "        allloccnums=rows['LocCNums']\n",
    "        loc_cnum_cluster_vectors = self.loccnumClusterVectorizer.transform(allloccnums).toarray()\n",
    "        \n",
    "        data_vectors = np.concatenate((data_vectors, cnum_cluster_vectors), axis=1)\n",
    "        data_vectors = np.concatenate((data_vectors, loc_cnum_cluster_vectors), axis=1)\n",
    "\n",
    "        \n",
    "        #tack on all the other numeric features\n",
    "        for feature in ['duration',]:\n",
    "            values=rows[feature]\n",
    "            normValues = np.array([getNormalizedList(values, self.maxs[feature], self.mins[feature])])\n",
    "            data_vectors=np.concatenate((data_vectors, normValues.T), axis=1)\n",
    "        \n",
    "        return data_vectors\n",
    "    \n",
    "    def fit_transform(self, rows, y=None):\n",
    "        self.fit(rows)\n",
    "        return self.transform(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro\t 0.6079854809437386\n",
      "F1 Micro\t 0.625\n",
      "\t****************************************\n",
      "\n",
      "F1 Macro\t 0.5714285714285714\n",
      "F1 Micro\t 0.5833333333333334\n",
      "\t****************************************\n",
      "\n",
      "F1 Macro\t 0.5714285714285714\n",
      "F1 Micro\t 0.5833333333333334\n",
      "\t****************************************\n",
      "\n",
      "F1 Macro\t 0.28888888888888886\n",
      "F1 Micro\t 0.3333333333333333\n",
      "\t****************************************\n",
      "\n",
      "F1 Macro\t 0.4692874692874692\n",
      "F1 Micro\t 0.625\n",
      "\t****************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Features Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.607985</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>Fall Duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Metamap Location Tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Metamap Description Tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>TweetNLP Description Tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469287</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>N-Grams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 Macro  F1 Micro           Features Removed\n",
       "0  0.607985  0.625000              Fall Duration\n",
       "1  0.571429  0.583333      Metamap Location Tags\n",
       "2  0.571429  0.583333   Metamap Description Tags\n",
       "3  0.288889  0.333333  TweetNLP Description Tags\n",
       "4  0.469287  0.625000                    N-Grams"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf=KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "abDF=pd.DataFrame()\n",
    "\n",
    "for vectorizer in [ablation1(), ablation2(), ablation3(), ablation4(), ablation5()]:\n",
    "\n",
    "    #SIMPLE PIPELINE\n",
    "    pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',clf)])\n",
    "\n",
    "    grid_params = {}\n",
    "    #SEARCH HYPERPARAMETERS\n",
    "    folds = 5\n",
    "    grid = grid_search_hyperparam_space(grid_params,pipeline,folds, training_rows,training_classes)\n",
    "\n",
    "    #CLASSIFY AND EVALUATE \n",
    "    predictions_test = grid.predict(test_rows)\n",
    "    \n",
    "    macro=f1(predictions_test,test_classes, average='macro')\n",
    "    micro=f1(predictions_test,test_classes, average='micro')\n",
    "    print (\"F1 Macro\\t\", macro)\n",
    "    print (\"F1 Micro\\t\", micro)\n",
    "    print(\"\\t****************************************\\n\")\n",
    "    \n",
    "    entry={\"F1 Macro\":macro, \"F1 Micro\":micro}\n",
    "    abDF=abDF.append(entry, ignore_index=True)\n",
    "    \n",
    "abDF['Features Removed']=['Fall Duration', 'Metamap Location Tags', 'Metamap Description Tags', \n",
    "                          'TweetNLP Description Tags', 'N-Grams']\n",
    "abDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: \n",
    "\n",
    "removing fall duration has no effect (surprise)\n",
    "\n",
    "removing information about the fall locaiton has no effect (surprise)\n",
    "\n",
    "removing metamap tags of the actual fall description HELPS (big surprise)\n",
    "\n",
    "removing the cluster information from 50mpaths2 actually has a large impact\n",
    "\n",
    "removing the n-grams of the fall description helps slightly (surprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training size vs performance (F1 macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for frac in np.arange(.4, 1.01, .02):\n",
    "    \n",
    "    partial_training_set_size=int(frac*training_set_size)\n",
    "    partial_training_rows = training_rows.sample(n=partial_training_set_size)\n",
    "    partial_training_classes=partial_training_rows['target'].tolist()\n",
    "    \n",
    "    vectorizer = myVectorizer()\n",
    "\n",
    "    #SIMPLE PIPELINE\n",
    "    pipeline = Pipeline(steps = [('vec',vectorizer),('classifier',clf)])\n",
    "\n",
    "    grid_params = {}\n",
    "    #SEARCH HYPERPARAMETERS\n",
    "    folds = 5\n",
    "    grid = grid_search_hyperparam_space(grid_params,pipeline,folds, partial_training_rows,partial_training_classes)\n",
    "\n",
    "    #CLASSIFY AND EVALUATE \n",
    "    predictions_test = grid.predict(test_rows)\n",
    "    \n",
    "    x.append(partial_training_set_size)\n",
    "    y.append(f1(predictions_test,test_classes, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Performance vs Training Set Size\")\n",
    "plt.ylabel(\"F1 Macro Score\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from https://www.kite.com/python/answers/how-to-plot-a-linear-regression-line-on-a-scatter-plot-in-python\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.title(\"Performance vs Training Set Size\")\n",
    "plt.ylabel(\"F1 Macro Score\")\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.plot(x, [m*xi + b for xi in x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioNLPEnv",
   "language": "python",
   "name": "bionlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
